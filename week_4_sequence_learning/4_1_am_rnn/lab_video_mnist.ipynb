{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Recurrent Neural Network Video MNIST Lab\n",
    "\n",
    "By the end of this lab you will have\n",
    "\n",
    "- Defined and trained a recurrent neural network with keras to perform video frame prediction with `batch_size=1`\n",
    "- Defined and trained a recurrent neural network with keras to perform video frame prediction with `batch_size=100`\n",
    "- Evaluated hyperparameters with a validation set\n",
    "- Defined and trained a recurrent neural network with keras to perform **accurate** video frame prediction\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "The mnist video dataset is courtesty of github user [despoisj](https://github.com/despoisj) and his/her [LatentSpaceVisualization]( https://github.com/despoisj/LatentSpaceVisualization) project.\n",
    "\n",
    "---\n",
    "\n",
    "# Load Data\n",
    "\n",
    "The following code loads in the mnist video dataset and displays the first ten samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAADUElEQVR4nOWV23PaVhDGd48kLsJC\nAeEyxjAe8Dh2mGI3bWeapn3o5aHTf7dP7WM6zTiTTmuaOGkJBmwDxsYGzFVClz19qN0gJCV+7XTf\njub89O2es3s+hMVAAADg8M5Az/I9wP818Pak8J3b3gZjCJwIAEC8ExCKyCEyZhYHDngXBDGeXldH\n3faECPAuKiir29tJOOoB5wDcX8XVA8jUwuMvrPOGYdgcALgfgsiQ6AbCSKL0uKhVjk4u5w5w8C+f\nCZJg2Q4HDoCCktv7VnHODk+ubv7igzBZTd/r9kYmcQ5CLPf53mrrr+evr291vQiTUoWNVFWksUMO\nhlKFvbzQ3H/VuiV8EEktfpOS0JrapgUstrmT4fXy/uW/hAdB6YP7H+3SiEwiDiDF84WV3svDpv32\nCJcRIbb53YPV41ql3tcdDlEtn6HaTzVrYfCWECFe/Hg7fFo+qF0ZNqGQ3srKlyfHg8VRdSMoap89\nyrb/+OVXw+IcBJYtZYXmSd9wnY+LCOV3C6HmwZOabhMHCKk7D5OTV3XT9R64VMTo5u4arx481y0A\nAIxltot25c2p5UIWVZiyvpV3Gs+qcwIAQGHr+53o6GLgSsulwpiaza12W9UzmyMAxhKlrzbYRXPk\nFllEUNRyCeh1Z8QIgEnZT78sxSa1N/rSy7aoIsoJiUhQ7ajlCEr2w0clTe+dduaAQeUjC0fJCms5\nZTI3I7mvH+7Ecdju9IlRkAqnYVtKOZpgGDbFc58Uknz8+lljaANCwFVyp1ezpgl1FTmIqbUNVRpe\nlZ/UR467lEWErD5NzjUlFpaSWkwRZtPfn5YbQ5sHl098rF9f3IsrsRVBi0aof/zzD4Oh43GCxdvn\nZHFzEomsrETS5PRf/viiY/5zJ8ENQ0CWMRVnus5p2j7Yb439zGap+TlwAIuHZN77rXw+87Wn5RHj\nCCCnNHV6cXg0sfwId/PffFI2Mup19c+W6e+BXkSUM8W0cN4YzANc04tIytr9pHXWGNkBiOdRwlBS\njY4HtbYRZM3LKsgiSUXs15qX8wACPYmxSFI2O5WeFSTiTYw7eles1K+9jXK7YdkrkcXXFbnd0c0g\nEa+9srASYqOpQ367/RFgDIEosBI/BBFgeUT+G/E310OGXuRAg1sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D18860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAADFUlEQVR4nO3VW1PbRhQH8HNWF0sY\nVN8NpnbIhAQTktBOcdrMdJqZvrXfth8gk4e0IZlAJlfskACuMLYJgmBdbOuyu33IQ7CtZdyXTh9y\nXrU//XX2rCSAkUKEr/V/qOnmQAhByhkHAAB5qvuqqoJ+EH02UxCiGfmc3z+2KUyZglKqsrp8bHou\niAkiQc4ZcABA2Siv3MrqndN+yIQEJVmRoyhiHDgSfeH7u7VB1+3agZCglCnOpyzL6jNKUSvfvlfN\nvHi6e+Jz4YMpM5W1SvZgn0tREMjG0trNAjOfmzYDEcHZpZ9+nUUc9ugQuZa+fm3uvPVq54sAMiZk\nY6n2w2qG9l0/DCno2W8L/Ohx3RpcWDJG1IX13yuJ5pvn9dN+xImezc+6jQeHlIsIJgobtTJtbG3v\ndQYRI0pxOc8PD9rOBTFO9NLPG6l3T/7c8kMOgLh4M+cfmE5wcdFIL0Sr1hbCd88e7Q9Czjlo2atV\nw2k0w4shoynyzMp62n67vTUMAQDAKC9fHTh77QhEBJPFYso2n334PGcirfxWVdpd2+cigiSZTinW\n/m6XcgTAZPbOL2Xoms5oyCjRDHRaLSciwIDIlbs/3kj0GnWXCwmgpISex5KBEkWYXPzu/poxODNb\nAYgJAHMdMjeve/0AS/fvbWRI76hzFl1CuPdR94i6kB6GVKvUqlnJ29lsOhRQtMmc2eB/KqaKQEFK\nX1kvaf3zlw+bHoPRGiF+j3rnRlKWvsllCjrtvdzcbNqMiwnwIPLtnj6TUJdyRkZ1rad/tI4pw0t2\nDDjjjA6chJoKtGTYfPTXnhtxflkKAOeMhsRXqZIg5+8f71gT6ycIAHAGDPSM7jcbuyfjnQPA5FsJ\nAFyZK8yTkzf1k8HkxXiCM7lSCY6237rjQxQRIudWy4bXbZ9FMY3EElTyqyXNaX90YzuJI5KWWkzY\n9dc9QcgkQTmZzuPp3gdHEBKToqYNzTU7n0KBiP3ye532frdPpydh7yBh/t2ORM8VM/3QPhxa1sSR\n/1KTv1ciK0oQ0n9DkBDCaNx5FBJAABCD/6r+Ac0KehwoRSG5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D51748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAAC9UlEQVR4nO3VSXMSQRQH8Nc9AwMD\nApMwAcrCGI3GqHGJS7mkSj+C39aj5UErLomiMTEkJkwWCRCWwACzdT8PLqlAN+Zs2dfpX//f65me\nBvg//pFBTjeLAAKentBQWFVcL+C/jPp3oerJaLjZQhxBCKEUf84gVE+fz050GutHfwoTEKKGwipj\nPgIiDZuXH09nNwp7v8sSESWcO5dJtRqVPnpuJHntxq2JyIeNmsukKURPz97OG/s70Sbr9WLZuVsX\nqV3bbvrSFKJmHty7G0Xo132HsaSZG1fLn1bLzh8xRLTM9YdzF1qVWqXVcZxAMwy9by1u2sdikND4\nzYVH47BbWC42egFRz5+JwWFx8YCDjNDE5Pyc0dl5u7RVcXxUI0Y+7m5vVXsgJ+npOzPa15evP7gB\nAgCaU4l6sdQPpESJXr6dapcXX1kOQwSiZ/J5zf62H6CUqPr0Fb328d2yGwAAIcbUZLZzZFUYyAiJ\npHRSLS2Xfq5KlZlnM0qr0vZQTkIR0qtubFYZEgASM+cWMnzfsk90coIQQqG9d7DV8ilwIGr+4b18\nqPllxUYpAeBBM3LYU3UIGEaz809n4926teuCnCBz60qgGarmumjef7JgQqd80AjkBMFr7/c1iCpR\nn2n5u1fTIWft9U6PyQmAy/0jIxHTdFCSl+YvRf1u4YXl8BEEuQ/ctyMU4smxXII668uLJZvjCAIc\nue/YIYViYiwXY43Pz1e+s+Nfi4gAIiIPKPWImQvX1t4sNQMcDBk6L8g4owqNjRu8vLSyxwcbERAA\nBIQzE6lQ13pvsaEIIQFQwuZk3N3dtBoiAVS0jH52OtZeL1Z6gociQkhi8lwu1CyWht6INIWmpvJp\nPCxanrAuUYqSvppmpdWyLQ4REKqOXUx61nrdEYcIiBJJmGrb2u5KhGiTKe/3WztV9/QEWXO7W7WO\nfIkQEf+g0KlXXUnzIsK8737XtgNZXcLCutz3pGUJr1dKKMfhb34UIUBghBBe4gQGD+KJ8QNOQ34H\nct1FrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D36780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAAC2UlEQVR4nO3VyVMTQRQH4Pd61oQk\nFeJIEAKBMkhKwLLcSg+W3q3yH9YDJ8WFAnFhKUgCCTHBJJBlzCw9/Tx4AIeeFJ61j1P99e+96no9\nAP/Xv7vwClsYAgn6C8KYogrBz40qPZYxAAIEYHrKmjTouNYfAkUSRE3XVRQcGIGemC0sm+77gedE\np6A+NrtgJZ1+x2O+l7RuzU37Z8bAiy4M1XT+7v1sun1StcGxs9NLuUTr1LH98/bDRIkXXqzc1ISw\nY47LhZFKxajx7sDmEEXY2OKjx3OZVrtaOT5zOOVMHfrVrfqFkDBRrGfPF2N+aXOz1B36upkn9Bql\n7dYFESJKtrgyb56U1taPThwuzKQxrtsHlTMXoghqc3duTYjSq7UtPyBCxlOTRmun4opIosTyC+bJ\n4Zu1I1cQACWmb1jYP2xwiiSqOZXD7+sftlwOAIiZQi7d7VVbf4SEiBH0vcNPtd+nMq34coGdNi/e\nSZggskGdl0s/BCEAJrJLT8aDaqXPIZKAcI6Z3ei4iECozjy9f11tfdkcwCjiNgOvyxWNCTKspaeL\n8Z/tSs2laEKB1/a1wBTIOaWKDx7dgH6z2fFHpQRe1zOZUHSV1Jl7y5bm7b6tOWIUEX5/aBomU1GL\n5x/ejoOztVrzaBQhCGDoOwi6kspmYqK6s1Ea0EgCRBT4DBHGrKm0Otxf/VznYXFpXgiIEEmbLyad\nHxuvJeLyIBMQoprIzZinu193ebh3GQEAgNi1iTQ2P5Z9iQAm+YbK9fmMZte/1MXlsuSEqVPFDJ3V\ndpsyISsMjdTMzaS9t9/1pFXLUmJWLh/vfdv7KetESjBTnNS7la9HvrQuCUEcX5xQ2pVyk0v2y4mS\nKWSCxmEvIkRWGNPGRO+oMpB3In35gdsdsV+2r04Augemc9AKT9YIQtTZ9gfl8CMxMkV09rjbCyKa\nl/0rkWl6EPC/IcAYIxKXhnEUQUAggEjyC5WSb/gP2qvWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D36898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAACyUlEQVR4nO3Vy08TURQG8HPunZmW\nTktf0lJCMUTA8IhBCYksTHSpf6xbty40EMEgCsqjUqClD0p5dKa087j3uNBE0t6puOcuZ+Z3v+/M\nIwNwv+7Xfyy82xX0D4KMM47ANIaaERsy2s2WLf8irQ8wphshXWekhTU2FM0mzLO9UgdEMOFmenI6\nEZPuDYZIDsdTJhw6rcqtZr2ER3Kzi89S0Rvr0teEP5JK6k7H1G7P0kMwlFt+PT3KhbT9ti8oaYS4\nax1fiOAULbm4sjyin9eOKue2w/R4DmWrWbmWgSkYzr18kWXO/uedI6srIsPZSU/Uy7U2BBHUJ5/O\nZFh1f22jfO74FJMyjK3CSdsLJsbs8/yQd/BufccTBKA74Thv7Z24FEh4+EEGq4UP62VHEgDGJkaG\nfbt0JgYQI2p262uftl0fABDTM2Pm5XX18vbwvePLi2LzdKfye1duPH7zCJt126NgQn5tN1Q7bEpC\nAIyNzi/FvFKxLSCYyG7RZlajCwiEfPzVYpJdfd20aBDxGjfM7UoGEvX41Mp0uH1xVHJgEBG2pwMw\njkiR/OzSGNiNsyt/EAHpSo8BAXKeXlxIGd7easWRgwgRCZ9xAMZC2aV5E93t9xWfBhEAAkESgGM4\nkU1i4+T7T7tX9H0vRASAYCRHM1FRXt+t9E6i+pAJkMCYfpIma+ttoa+WigAQaJHJmZhb29/s9M4O\nAExBAIx4Ph9qFSo3nuKkKgVYYjwbx/pG0euvpU5BzEyNhOTpx4JKKFO4kV9Iy/Nq3Va2VqXokYm5\nlHtavuoqiSrFHM/GRW31S0fZS5WCww8zUa+2deDcnaTncppVb1ii/5yaIJi5iF8/vgjopUzRwmAf\n7l8qHwoox2eeVb3eLbYDhIIgOmcu/TgK6qW8yY1vhiipXsg/e/Yf4bGE9FsdGWQUKdSRJF0Z1Ev1\ne0WGQEQQZH4BQg9UEZNRd4gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D36748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAACtklEQVR4nO3VS1PTUBQH8HPuTdL0\nRVtpy6NqrcggCAzWhehav6xbvwALHXEGBsZB+nCKtrT2SUvTB3kfF8440Nx0546zzLm//G9ycyYA\n93Vf/7dQcI2hxBWZB4KKjOCY49HIcW+1Jc89GFeUgBoKBqKJcJCBo7Xqlj6PMDnxKJtbCHMGaljm\nEietdjru2+RLUFlc29vZjIVs0wAZWUiF0eLwVLu9ZoawhZf7bzMJdDVzZDhcXglJakSxHfIlGFrO\n7++EodtudIa6pYYxKoGp67Z/CovnXr2IunrxqFCfGG48FVnherc3sXwJU9bzjyNuvfTlqNE3XJqQ\nzt3hRcNw/Ym6/SbNjNLH44LtEIKqswANSzVrDpHVgFkvfTpumC4BYOxJKqSPf/fviBnCwRw2P38t\nmDYAICY3ltSJ1r52/IljVOLJznnTIQBArj57l6Vea3Lnfc0Q1/gFsWGl7xICYDSzuRu6qV5MnDmE\nzMthwBzcEBIge/h+L4qTk+MRzSOOdiO5lgOAJIWzr9eU6aB6acA8ApbDkQgAQX6Q212Fcben2fMI\nkEv0d4J4bPt5QrHLh02L5hIgIgQEQB7f24pw6+ygNRviHTECIECUYtkVrvUqlfHsAi8BAgBgkWRm\nEbtn5YYnREAAAFDObaVk69uHou16mj5EfbqVgPHF4cArfIgUWt+ImL3u1eyZAAAwIQmnM8vK1clP\n3RE0hSm4sJqO8eZBUSSEKciz+TQ3epWecAsiwqRsPk3jTm0gJKKNKdGl5cDwrDT2nolfSjCVSvLB\n9x9T4aMISWxtKej0y1VL0BMTjGYTbNSqdcX7EqZEVyNOp9oeCU5eTJBJij2olK49g+KfwhCm7fPi\n7Mj/K+9LRhyU+4FCS/R5+RCAQTGIlSvTL8X7r0QWXuCgTW3XxwgIcgbkEhGIzR9b6TZqQYthMQAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D36C50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAACtUlEQVR4nO3V21PTQBQH4HM22TRt\nWkpv0xaLdgSGGZEB9dl/3gfxOjqCgiBQMlJgektTmjSX3eODT202Hd51H7PzzW8v52QB/o9/d6D6\nGwICIoKURIvTugIgIDJkjCGGsUiQxRTGM1krZ2SyZtbMGtwddm6dcF4tpDCjUCpVK5ZVXCmuFPLZ\n3tW7r2EslhBmNV9tN/ImY5wbpmmaRg64J+7lElLaeP2iyeUsCGNgiKxoabNfYy+dIG/v77QtGXmT\nwb0ArbBazheb63f9uTOYI8x4vPOopE19+7znCtSqTc3KFst5lr4XZqxvlXTwup8PRj4w3tooNTQz\nl0VMTeFWpZKhsPvl8NQPUDMKIeggw2DJIXNrpciFf3Vw3BUEuhFxw4iCiT9fAXNExjOPTy+Oz4ch\nETKy1lZ5FA4nS+5FhuMeDX78vHZiAAbaSqvIyR9NZHpKND7Mt2f2KCYkRLPSeroqx33HX7KX2Dul\nW+r0IgIEtNbWGmbYtZ1l25eR7V6w+0kQEzEsbq1laHx06MSQTkC6/kgTIhYEoJc26+jenF1OxbJK\nJkExQ5JEgLy8WRH9y6u7hdpfLH6SJAGAAI1KvZ6bnby1pwvrSnQl0d9GxkytWTG8wzfXs8VWTjYy\nAAGCVn75zHIu7X6QaH6mIADArMbupjn8/nuxi9MJf7K7UZX2wbWQiTk1wczG85YV350Mkj+YFKLl\ntvfK6LkDX7VoJTHL6y0rHjvTKBmSQqxavZqJBm4gFJNKgq29Oge305eKECVB9ni/ptPksvdgwvRa\nuwDCvXaUq1YSvtrIymjSdVQhamLkcpoI3P5UmaKqMWRIcdCxR7MHE4Bgqjsfv42jBxOKb49yw09n\nfrK+0oiMOu/14Qc7WcTpJO746N2khKifV+S6FEJ5jykEkDFSPMXLCCBAGgD4A5GVUTPEFl77AAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D36C88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAAC0ElEQVR4nO2V3W/bNhTF7yUpSrJk\nO/FHln4NzZai3bB1aF/6tP+/LwUKFGkQwG1ad0scOJZj2TJFieTdQ5I2tiX3dcB2Hqn70zmXl5QA\n/td/V7i+wBhDRGQMGQfShbXrFWKd4EJy5FxI7kmgZJaT2+4iwr1uP5RE3PN83xPj0el5WtAWF/R3\nDw8ftyNdIPP9oBFdfG6QNrYeQe/+sz+f9rhLF4VFQMbbD5PlrMxpC/Lw+avDQM9tVioSBrjsPJp+\nmut6hMmD3/ZjVMvzj8kSvKDT7TXa/d3LOVEdwoP9g11psouPR2mOMsxc3G73OvF4pZkVRDR6eyGj\nqw/v3xVWBCFvURj2+jHDWhcZxZFwOvk8mlgQhqgRxS4MPFa/YzKOfFaqZHipCC2TYmenlXuCI9Yi\nRivFs/PRVFlgwL3WXlNaNIbqd8yodMbS0TjVBITca/YjT7vCbJm+vjo9/rFcFMgQwLFG3JQ2m6f5\nFqScD9ozdpYUFhw69H3psouzqYJ6xOnjdCDT8WxpHAD4mFt1dDTKqL59MmN1JUu1yA0heU2Wqsn7\nwVQT3B3M6kl2uVECrbGWOAZdMf3r0/EwLaHeBcCVjjFyRMiDZsedn5wMk8IQIVAdQuQQARCYiFo7\n9uzkXaZhTWx9AYiICL3dZ0+6+vQyN3Q9yG/Z1u8+ABAAsnj/l8OWGibaEiDAlmC3kj+9fNEtF+Ol\no41nm8EAAHjj5z+e9EnNtKNr3+8iXuvp83uBLcvbDxLdOZmVCMZ7jx40JaPrWAT1F/mr2vd/6Agp\n2E0pEdRO/8aEPfi976FZanfbyF2XqmDI7v3a4VBm+c3rV69YJcJb/ZCBWeTW0UrnW1zCpgeUX2Vu\no76mF0AAsCYdTkwFUY242d+RTT6cTipmX404M3zLOoM3g0kVUYmQHb6+jL4MJhvn/mvsTflBU8xV\nvv7/2oZwLrE0tjLXv1f/AMXhc15OS1PjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D4DBA8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAADEklEQVR4nO3VS1McNxAA4O6WNJqd\nfS8LOA4JxnElFce5+Zj/f8yFQ+KyCztkWWDB7CzDPDR6dC4pzMAM5OhD+iZVfdVSq0sN8H98jYFd\nmwgIDMz/hSAgAiIBIXsfHpp7BKWO+wSEUpJSoU7T0oZ7RDaXQs+2d6NAQutIJ868/7TK7h+uQZDG\n37x5sS1cWSHKKBao+9Hy2vIjRM5/+u3nWagurkoHMk4SHZdl5X03ofjV29ff69zkq03FUX889v3p\ndF03a9Agsnfw5sU8FPnlYl2AHhVWydGwV7huIpLdvRFVlx/e/VlYijdFPYzUQN8rUWOpkuksZnP1\n6a8Ty7LHiRXJVj7JikbRmmQwHEhTXS0uUhCsQfW35oaWaRo6ie73FLGvy5qRZJxsPX8+N3Z3deq6\nDobRIBII3nkmGeneaGd/b1JWz44l+Q7CdVZUaEsfxT0VD2fz+c6oT8PpUFLn9avsJhemClrrKOkP\nBqNxork37KtHyPr8DDzqREs2mYzSG8llxUJL5A5Spx/fGbXJrffeGBbnp2WvWGVOCbpTswZxxaH/\nZXB9fHJ5bVnU4Sga6Sxdb4RE7CBcH7tiYC7ONrlnIfJz1JSX5hqFdKGD+LVJY6oyUzOw9amxtQmC\nUarwJU2zf9jlXpG33gMh+PzG1JalUkyEwK0EQnBIAACEhFyWxgQUWgeiriwAwBAAkVQ8jKW3LjCE\nwEAkuCMLADAjICWTLVEXzjMDMyAR3X4sDwkAMMX7383KBXkGRCKB/otoJYxq9Or1eJVdAhKTkCow\ndLzLbfR2fn0bH52cyRCAojiqzZ0/sI0gTvYOXgp7cPG394EUsbdPEMDZ/rfPuPrx9ENtLSh0pnZP\nZKHtH2YR96bjUWVKG1wwzj9xF5y/HEuOB6O+RBOCs9Z1dfJtFqGIgowk2qoywTcHQHvFfO0DBFfX\nRV6ZEEL3p/RvsE8XBxay0+XyprCe7z5KFwnLw4nxx7+//1zbhzOpnRyVxR9ucbgsQsvka++xLNBH\nvz4tfMuobB+vAEgEoWVOPkIAAaBdfL3xD4K6vJDLYf/DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109D4DC50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAADTElEQVR4nO3VS28bNxAA4BmSS+5T\nK0uKrDS2a7vxoQV6KmD0/1/bQwukTtCkSf1SrFgrWVrtk0tOD0GcyNYqxwJF50p+GMyAwwH4P/69\nQGw9eXwVGWOMMWTMaK2JvkYQhSOVlI4UUuXL2VKb7QQdfzjYkZxxKbh08/T8OlmZB3nEOnF3f/rh\nyGlqgwhS6fyFbyu7jXD1/MfTk57JprOyMtIVqKLQM5q2EO/k59NnPMXJbJ42wo98CkK/aLYQGR+e\n9F2b/v3i5aIkGUZxU6LgzLYSVPE3+7HIbv98dZZrpoI4lUScI1IbARV1IqecvPntXdJYZkFwBQaR\nbSlfRaHHquT9ZVIQIjDhugJt0TRrTVuvJfQcrGbzVW2RCbczGIXu0i2qaq2YNSI8yZBL15XScYP+\naP8gkmmPoKCmjTiKM+ZEnSjXbrTz7PC754Gz7NvypmklWZJWkqveoZp3u4PR3sGu4oqKu3NT02ZC\nRZKWnKneAfd6/d6TQRxIxsHcDLP0iwasZclni5VkYW+YFzpZza6TLPSZVoPjVaKbzaScj69QWgum\nqhoUMpl1Y1cJtdt1bQupF2fdOs6u/np7mWtCfv5Ht9vp71ZeFOrP1awRU75x6l518Xo8qTQhzpUf\nRoO9gHv9orivZo2QvsimXZiO08wSIdb5QqjxZG/fH94taSMBW0yth3laayBAAMK60lYExlfifqDX\nCeimYAhgCRCIiAAaY9zYVdK5/wQeECBLiIAMEawlACAyunKEq8qWLAAWgSHnDjONRguIQLYBR7qr\nVgKEhMKPnSyzhADIhPIDz3XYp0F7TIAQvMFhmEzGBSHjqtMb+Ix/Pt9AALB7dDoavyxnJITojA6+\nrRd1bTY3+RPpHX2//9Q3V7fKFeHwSVDMV0Vbkz8K7B8fHj/tuK9eR57wugEub+b5VgIQDju+o7UT\nhm5mnGp+/X6hN7+x+/BjT8ohd4IOH8/r5fXlTd5sJUR5WgN3wk4Pi+nV3e2H5Msfc2MWWlydVBIZ\n1XlycX47n5dtg3wvzLtf9gdxc/f21w+TcZJXtaGvEbo9G+U75u7s92S2LI1d32SbN6JQu/2IstlU\na2PhwX5pWaJMKgV1VT3elK3k48mG+/+x+AeXFKbEUR2JPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=50x50 at 0x109DC7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pickle\n",
    "\n",
    "[imgs, y] = pickle.load(open('LatentSpaceVisualization/Visuals/mnist_transitions.p', 'rb'))\n",
    "for img, y_ in zip(imgs[:10], y[:10]):\n",
    "    print(y_)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Flatten Images\n",
    "\n",
    "The following code resizes each image to `(28, 28)` and normalizes the pixel intensities and converts `y` to a categorical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6000, 784), (6000, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "imgs = [img.resize(size=[28, 28]) for img in imgs]\n",
    "X = np.array([img_to_array(img).flatten() for img in imgs]) / 255.\n",
    "Y = to_categorical(y)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# keras RNNs with `batch_size=1`\n",
    "\n",
    "## Question\n",
    "\n",
    "- What shape do you need to convert `X` to to make it compatible a with `SimpleRNN(..., batch_input_shape=[1, 6000, 784])` layer?\n",
    "\n",
    "## Hints\n",
    "\n",
    "- This is the most quick-and-dirty way to make `X` and `Y` compatible with a keras recurrent layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question\n",
    "\n",
    "- How about `Y`?\n",
    "\n",
    "## Hint\n",
    "\n",
    "- The shape for the transformed `Y` is identical to the shape for the transformed `X` but for one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Reshape `X` and `Y` and save them into new variables call `X1` and `Y1` respectively which satisfy the above requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Define a keras RNN model compatible with `X1` and `Y1`\n",
    "\n",
    "## Requirement\n",
    "\n",
    "- You must specify\n",
    "\n",
    "```python\n",
    "SimpleRNN(..., return_sequences=True, batch_input_shape=[1, 6000, 784])\n",
    "```\n",
    "\n",
    "as the first layer in your architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Fit your RNN model on `X1` and `Y1`\n",
    "\n",
    "## Requirement\n",
    "\n",
    "- Fit your model with `model.fit(..., batch_size=1, shuffle=False, epochs=50)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question\n",
    "\n",
    "- List two downsides of using `model.fit(..., batch_size=1)` as opposed to `model.fit(..., batch_size=m)` where $m > 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# keras RNNs with `batch_size=100`\n",
    "\n",
    "## Question\n",
    "\n",
    "- What shape do you need to convert `X` to to make it compatible a with `SimpleRNN(..., batch_input_shape=[100, 6000, 784])` layer?\n",
    "\n",
    "## Constraint\n",
    "\n",
    "- One batch must complete an entire epoch\n",
    "\n",
    "## Hints\n",
    "\n",
    "- A batch size of `100` means we effectively have `100` copies of our RNN each of which are being simulaneously unrolled on their respective portions of the original input sequence\n",
    "- The answer will be of shape `(batch_size, timesteps, 784)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Reshape `X` and `Y` and save them into new variables call `X100` and `Y100` respectively which satisfy the above requirement\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- There must be no overlap between batches (i.e. each image can only appear in a single batch\n",
    "\n",
    "## Hint\n",
    "\n",
    "- The simplest way to achieve this is to split `X` into `100` different chunks with `numpy.split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Define a RNN model compatible with `X100` and `Y100`\n",
    "\n",
    "## Requirement\n",
    "\n",
    "- You must specify\n",
    "\n",
    "```python\n",
    "SimpleRNN(..., return_sequences=True, batch_input_shape=[100, 60, 784])\n",
    "```\n",
    "\n",
    "as the first layer in your architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Fit Your RNN Model on `X100` and `Y100`\n",
    "\n",
    "## Requirement\n",
    "\n",
    "- Run your model for `model.fit(..., batch_size=100, epochs=50)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question\n",
    "\n",
    "- Describe the differences you see when optimizing on `(X100, Y100)` as opposed to `(X1, Y1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Split up `X100` and `Y100` into variables `(X_train50, Y_train50)` and `(X_val50, Y_val50)` and re-fit your model with this validation data\n",
    "\n",
    "## Hints\n",
    "\n",
    "- `X_train50` and `Y_train50` have shape `(50, 60, 784)` and `(50, 60, 10)` respectively. Their validation counterparts follow similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Modify your keras model to make it compatible with `(X_train50, Y_train50)` and `(X_val50, Y_val50)`\n",
    "\n",
    "## Hint\n",
    "\n",
    "- Re-instantiate your model with `SimpleRNN(..., batch_input_shape=[50, 60, 784])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question\n",
    "\n",
    "- Why did we choose `50` for our new batch size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Refit your model with `(X_train50, Y_train50)` and `(X_val50, Y_val50)`\n",
    "\n",
    "## Hint\n",
    "\n",
    "- Make sure to call `model.fit(..., batch_size=50)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Design and optimize a recurrent neural network to maximize validation accuracy on `(X_val50, Y_val50)`\n",
    "\n",
    "## Hints\n",
    "\n",
    "- Stack multiple recurrent layers\n",
    "- Use a convolutional layer between the recurrent layers and the image\n",
    "\n",
    "## Requirement\n",
    "\n",
    "- The only recurrent layer you can use is SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bonus Activities\n",
    "\n",
    "- Use more than one batch per epoch with keras stateful RNNs\n",
    "- Use overlapping windows instead of disjoint windows in each batch\n",
    "- Monitor gradients during training with tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
