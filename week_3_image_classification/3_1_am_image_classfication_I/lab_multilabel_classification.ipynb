{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Multi-Label Classification Lab\n",
    "\n",
    "Welcome to the Multi-Label Image Classification Lab! By the end of this lab, you will have\n",
    "\n",
    "- Implemented a multi-label image classification model\n",
    "- Gained intuition for how a CNN learns to predict multiple classes\n",
    "- Used data augmentation to maximize the effective size of your training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load MNIST Images\n",
    "\n",
    "The following code loads MNIST images and normalizes them. It also displays the first five images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy\n/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/H\ntn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+\n/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/f\nv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y3\n5wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x10B1E79E8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv\n/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL\n85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C\n8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo\n3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7p\nVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x10A7B8780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMT\nAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjw\nFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/\n8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEV\nj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x10A7B8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGPyg5u9/e1xyCV9+\n/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65\ngA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fg\nCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0QsY6cRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1124BDBE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nN3QPwtBYRQG8EMU0e0u\nZLIw+QKXRZlMGC0GX8CglE0pk0VxPwQmE5YrJYPVIjYMlImSwXNiMOi97319AM/6O6fzh+g/Y5hr\n5mrRNByseAZba4D7EnlSN8wy3uAYXJOwDEw0ohKwD9mtxehqRLQBCnZr8GPkJ/Ll79y0m37GiIji\nK2AQsGMYiIbryyvjmZO20U9gAIcjTg43GhfethOROToO+En6xRUlZhnSjd+I6BY7xVIRY79w4Xap\nR9IOSTWWYSWUqE0xlH771R7UrULefm5U2pxVCt0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x10A7B8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import array_to_img, img_to_array\n",
    "\n",
    "[X_mnist, y_mnist], _ = mnist.load_data()\n",
    "X_mnist = X_mnist.astype(np.float) / 255.\n",
    "\n",
    "for x in X_mnist[:5]:\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    img = array_to_img(x, data_format='channels_first')\n",
    "    display(img)\n",
    "    \n",
    "X_mnist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Concatenate Images\n",
    "\n",
    "The following code creates images of the form\n",
    "\n",
    "| Left | Right |\n",
    "|:----:|:-----:|\n",
    "| $\\mathbb{N}_9$ - $\\{3\\}$ | $\\mathbb{N}_9$ |\n",
    "\n",
    "where $\\mathbb{N}_n$ are the digits $(0, 1, \\ldots, n)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAAcCAAAAAAR0CPiAAAB3ElEQVR4nO2SQUiTYRzGn5nMNS+1\nMGwwUlxC0sFBgYeKT1C0QMQWDvGql+gSYTsJSlIIndMGc3gQjLRGh0JipE5ZJQqlKBiucqAYDGol\novs/zJPLvd/rzh18Tt/7PO/v+b/f973AsY6UJWd1sr7u3O2M95W665oPzmZLJhQPbepKnN4YSbJF\nDdwUEaGIrLvNmP3RFpmevF/WbVejIQZdN3e/tbuCckfNbN1/yPS7Wu37PGHAiokKwDCBF4IkA1e1\nGOCgDMIBwJCnSuQnp+qKjuCA6zEmqgDc4rSSxDlnB0o9Hs9pLVnySdbdsM1Kgwn84Lsb/U4y4ruo\nI88M/ko96JW/qh8nSUoymfzN1EPTZwWAioTIF4/qxsj5Z12tAM72pTlm0YCYFFlxqOaN4RZr9pm8\nZMaKfZn4Ckd0jQcqeM1lk3l5QQZOWQOiuTn/NM41xSns/LlUCcCQuWx9voasHg9EGlcBALY8u068\n4edcp43jLgCAIYt5wF6yNcco/rpzBQBwfpVtGsAoBYD698LR3N9hSBgA0LEm/bpJwXB5uX9GuDdV\nojSK31pQ7Y3sbNUU6sAekmTybaMaVKcYCYvwedUh89ChbPeayl58jCbMlc0vwxtYiv7Y1s37/7UP\ndrvJi2WDJtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=56x28 at 0x11F1437F0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAAcCAAAAAAR0CPiAAABgklEQVR4nO2RyyuEYRTGn9EgTS4p\nGbGUcllIkSxcpim3EpqkLBTZ8BdIDdmSjVIuCymlKZeFLCxmQSllR0QuuYSNKL4+l+d8nwUL05x3\nYamc3fv8zu9873de4L9+VnHLrkirzl5dp86ghaJCks+lX0dvDPS5jkHLmG1OwtPObWdquobnRPYL\nNBC+J69CWcCa1BjEGSXO3RK+DPqBiv4bGdDFt9b41DsmzmY5kDNkiTiiXCl1VSxlXB95ngHkX5Pc\nWLoLx3cERBWHyffpvMIL4XqlF6MN8R3+qHA8Pi6KUGhdUsLJytjvL6rL8RUtkuSK70eWYJgRU9Zh\n17bH46mp8hoaAiJ2mUqCD7x7FE7UGkVtOQAsfnRU39s8G/6dWC+cB9B7RvZofFwkoopTwnYAaDqm\nXa7wW5E2VTxw9lIAAO3iLn1Fpj3Fluuu2QBqG7td51QRT7INoo2Oo5KS6rREYHlO4QHTVfuFJIVb\nCyGVB0RGVJA5eUVyMmj6MX/U9I5/uj4BUYe5aZBe4r8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=56x28 at 0x11F143B00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAAcCAAAAAAR0CPiAAAB10lEQVR4nNWUT0hUURTGP/+kCwum\nlFAEoSaiwnFRi0hUdKPYNqWFtYkgmCQwLCGbRdRGFEo3tog2KSouWiShCyPInYlNLdpMGBYpk4sE\nG8dxfjMunm/evD+I0yq/1bnfub97znn38qQDozwrDNRodfYfjih4DNFma12yX/AWwA1rPeLIB0dS\n30Kh0y6ubR1YavcGuybj8SQAyzed4G1g5rC8wJ51LK2cMczC3WRNrxR7teE5RJFx3vfppfIuHZ8M\nZOfOR4C7tu2XM1EIgLBfd6JAxFbx7Anp2ZANfJuJvoxKUtX77fJiSWHbrg7gkWefGbUbM/6ps7kJ\nGDOKXxqKxSJXPC7xOQCvHfeRZuuiJKnhBwCDhS6w/iPQ6XO4KYwB67d2v3pQTU7y2BTMlDnMNMu1\nkopHgejPVQi6Xo5U+hk6JUmHrpneFPyuU+Mw8Mmvbm9Qc7AoScr3m1YH8GthBYi3nOve4E2ZB3hh\nzQQtVX8lW9M+9yPXkTHcoE5GMtTmhwmfssGjeZJUMg7w0NVHIGSCTwzDAvtevjhVOTALsFhlmtYf\nIP96m6T5Qf1NSpLu9ZuZdMqMkq3vXBX3UNzsJXE/F0x6kDC4p1dz46TaTSDcW5Er959oB6dfEOiz\n6K8uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=56x28 at 0x11F143898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAAcCAAAAAAR0CPiAAABzUlEQVR4nO2QQUiUURSFj85ouhCS\nUGpAJiXIQVBBRAQhTRTUVRuJcHSli1ZODELgJnDjQlFnJUigKw0VUUGkRIIWLtQIzdKFEkOmjaA1\ng1N43/ld/DPq+50/0rVnc+89533v8h5wozOVLBqzxdfgMiZFyYeilCuDgyLRoEi31XcFet3/4p4c\nbUV2c171SEvcSTKLe/lOeAlvNxerAAChJZ3L3k5rH0MI6TuRB3ryNEqSZNAsxzt6nKe+ZAEARiMv\n9Bs/83vn2h7PpYPrMmc2frUas5wAivM6PRjp6rqfa3qv3djWQY8xkejlEZJfXWejY4Ps0Q4UqPEM\n68ZkAFHg0/Pd+KnU/nyE+zWwDlPhRBuHOHX3fGon2arl6ftGU6z1Gx8vBM4sx4VpgfzxUAO98rch\nHqr5RKsB4NEJqX85vBJ/h+sgWh1rk61gvQN4YzU3YnX49uGCzUKfkG1JutcnfrPx/5FpG87zjTzM\ntZheNQMAjsdKhUttwHGSbVbTKz8zgewOkVCFDfeMpM9pde8dqHe1tStK9ittOLykwfLLdrMSEVHv\nbbnCY3Li0j8DaFwTCTSk2XEoIzlkm+rS7v/1Gwj+J6irZqD+1rXAK+gU2WPHDponaakAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=56x28 at 0x11F1439E8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAAcCAAAAAAR0CPiAAABkElEQVR4nO3RP0gcQRiH4Z8moGhh\nwD+nYkq1VkQOFSyEEAmoiGksFAmekkpIk9RpI1hJ4GxEQYhw0SJiBC3UIphKBOFC5BQkIIoocd3b\nS941xYphb2eKdCmcZpd3eJidb6X79U+r47LBvBGb8v3lVqsrz7Bh3JjwAHIpi3vwiYtmQ388mQMA\n1wK7od3UX4MZFg3EJanqOwvFBlf3DWZrapqicIAZSYVJrhtNB64BPWr/GIH1B0xLaoVx4w124Kzr\n5QV4I+EPXeZrlaTPpKtt8CoNuC/CPQFPJT3zeSI1bizlu1g6mMz1aLiXHoP7ZW8r6+M6jkd/PuwN\n3GaL8qEfrBvf9387yfy5Du0CcBi7Kw+Dh9P1Sj+KyxJaz2yfOpthNdanjhJJcndOjPdXktXKaO3J\n3v75K/O8pXiWQUN+G7DM/pjF6T3pimh99BOO5qEtnAv/vtY+1/RZFK6USJ0F8nK28/SG85ghZ4G5\ncxatrvqYd6YejMZrssJhiJt6CuDXB6tTWWqxwLhxCSTs7v9ffwDvy+UDmuBxMwAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=56x28 at 0x11F143908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "nb_train = 10_000\n",
    "nb_mnist = len(y_mnist)\n",
    "\n",
    "X, y = np.zeros([nb_train, X_mnist.shape[1], X_mnist.shape[2]*2]), np.zeros([nb_train, 2], dtype=np.uint)\n",
    "i = 0\n",
    "while i < nb_train:\n",
    "    j, k = np.random.choice(nb_mnist, size=2)\n",
    "    if y_mnist[j] == 3 or (y_mnist[j] == y_mnist[k]):\n",
    "        continue\n",
    "    \n",
    "    X[i] = np.concatenate([X_mnist[j], X_mnist[k]], axis=1)\n",
    "    y[i] = [y_mnist[j], y_mnist[k]]\n",
    "    i += 1\n",
    "\n",
    "for idx in range(5):\n",
    "    x, y_ = X[idx], y[idx]\n",
    "    img = array_to_img(np.expand_dims(X[idx], axis=0), data_format='channels_first')\n",
    "    print(y_)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Transform the list of lists $y \\in \\mathbb{R}^{N \\times 2}$ into a categorical numpy array $Y \\in \\mathbb{R}^{N \\times 10}$ where $Y_{ij} = 1$ if $j \\in y_{[i:]}$ and $0$ otherwise\n",
    "    - $y_{[i:]}$ denotes the $i$th row of $y$\n",
    "\n",
    "## Hints\n",
    "\n",
    "- You are essentially implementing `keras.utils.np_utils.to_categorical()` but for multi-label data instead of one-hot labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Multi-Label Logistic Regression Classifier\n",
    "\n",
    "The following code creates a multi-label logistic regression classifier to predict images with multiple MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                15690     \n",
      "=================================================================\n",
      "Total params: 15,690.0\n",
      "Trainable params: 15,690.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.constraints import nonneg\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X.shape[1:]))\n",
    "model.add(Dense(units=10, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question\n",
    "\n",
    "- Why is `categorical_crossentropy` a poor choice of loss to use over `binary_crossentropy` for multi-label classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question\n",
    "\n",
    "- Why is a sigmoid activation more appropriate than a softmax activation for multi-label classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Question\n",
    "\n",
    "- What piece of training information do we lose when we convert $y$ to $Y$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Callback to Measure Accuracy on Threes\n",
    "\n",
    "The following callback takes a set of images and filters them down to only those of the form\n",
    "\n",
    "| Left | Right |\n",
    "|:----:|:-----:|\n",
    "| $\\mathbb{N}_9$ - $\\{3\\}$ | $3$ |\n",
    "\n",
    "It then flips all of these images to make another set of images of the form\n",
    "\n",
    "| Left | Right |\n",
    "|:----:|:-----:|\n",
    "| $3$ | $\\mathbb{N}_9$ - $\\{3\\}$ |\n",
    "\n",
    "The model is evaluated on how well it predicts the presence of a 3. Concretely it computes multiclass accuracy on the digit 3 where a prediction of class scores is deemed \"correct\" if the class score for 3 is either the highest or second-highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import copy\n",
    "import keras\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ThreeAccuracyCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, X, y, plot=True):\n",
    "        three_idxs = np.argwhere(y[:, 1] == 3).flatten()\n",
    "        self.X3 = X[three_idxs]\n",
    "        self.X3_flipped = np.array([self._reverse(x) for x in self.X3])\n",
    "        self.nb_3 = len(self.X3)\n",
    "        self.plot = plot\n",
    "        \n",
    "    def _reverse(self, x):\n",
    "        x = copy.deepcopy(x)\n",
    "        left, right = copy.deepcopy(x[:, :28]), copy.deepcopy(x[:, 28:])\n",
    "        x[:, :28], x[:, 28:] = right, left\n",
    "        return x\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        Y3_pred, Y3_flipped_pred = self.model.predict(self.X3), self.model.predict(self.X3_flipped)\n",
    "        y3_pred, y3_flipped_pred = np.argsort(-Y3_pred)[:, :2], np.argsort(-Y3_flipped_pred)[:, :2]\n",
    "        \n",
    "        logs['3 accuracy'] = np.sum(np.argsort(-Y3_pred)[:, :2] == 3, axis=1).mean()\n",
    "        logs['flipped 3 accuracy'] = np.sum(np.argsort(-Y3_flipped_pred)[:, :2] == 3, axis=1).mean()\n",
    "        \n",
    "        # Display sample image\n",
    "        if not self.plot:\n",
    "            return\n",
    "            \n",
    "        IPython.display.clear_output()\n",
    "        idx = np.random.choice(self.nb_3)\n",
    "        x3, x3_flipped = self.X3[idx], self.X3_flipped[idx]\n",
    "        x3 = np.expand_dims(x3, axis=-1) if x3.ndim == 2 else x3\n",
    "        x3_flipped = np.expand_dims(x3_flipped, axis=-1) if x3_flipped.ndim == 2 else x3_flipped\n",
    "        y3_pred, y3_flipped_pred = Y3_pred[idx], Y3_flipped_pred[idx]\n",
    "        display(array_to_img(x3, data_format='channels_last'))\n",
    "        pd.Series(y3_pred).plot(kind='bar')\n",
    "        plt.show()\n",
    "        display(array_to_img(x3_flipped, data_format='channels_last'))\n",
    "        pd.Series(y3_flipped_pred).plot(kind='bar')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fit the Model\n",
    "\n",
    "The following code fits a multi-label logistic regression model to the multi-digit MNIST images and uses an `AccuracyCallback` for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a26bae2017dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnb_train\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnb_train\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnb_train\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnb_train\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "X_train, Y_train = X[:-nb_train//10], Y_train[:-nb_train//10]\n",
    "X_val, y_val = X[-nb_train//10:], y[-nb_train//10:]\n",
    "\n",
    "history = model.fit(X_train, Y_train, callbacks=[ThreeAccuracyCallback(X_val, y_val)])\n",
    "pd.DataFrame(history.history).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Display Learned Weights\n",
    "\n",
    "The following code displays the learned multi-label logistic regression weights for each digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "W, b = model.layers[-1].get_weights()\n",
    "for d in range(10):\n",
    "    w0 = W[:, d].reshape(*X.shape[1:])\n",
    "    img = array_to_img(np.expand_dims(w0, axis=0), data_format='channels_first')\n",
    "    print(d)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convert `X` to TensorFlow Format\n",
    "\n",
    "The following code converts `X` which has shape `(10000, 28, 56)` data into a variable `X_tf` which is suitable for use with TensorFlow and has shape `(10000, 28, 56, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "imgs = [array_to_img(x, data_format='channels_first') for x in np.expand_dims(X, axis=1)]\n",
    "\n",
    "X_tf = np.array([img_to_array(img) for img in imgs])\n",
    "X_tf = X_tf.astype(np.float) / 255.\n",
    "X_tf_train, X_tf_val = X_tf[:-nb_train//10], X_tf[-nb_train//10:]\n",
    "\n",
    "X_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Define a CNN model to maximize the accuracy of both images with the number 3 and when these numbers have been swapped\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- You may only use `Conv2D`, `MaxPool2D`, `ReLU`, `Flatten`, `Dense`, and `Sigmoid` layers\n",
    "- Use the `ThreeAccuracyCallback` for evaluation\n",
    "- Use the `adam` optimizer by specifying `keras.models.Model.compile(..., optimizer='adam')` and do not adjust the default learning rate\n",
    "- You are limited to `X_tf_train` and `X_tf_val` and may *not* use any kind of data augmentation\n",
    "\n",
    "## Hints\n",
    "\n",
    "- Use your intuitions of max-pooling and convolution for narrowing down your architecture search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Question\n",
    "\n",
    "- What architectural choice was necessary to include to increase prediction on the test set? Concretely, list the hyperparameter values that worked. Justify why inclusion of this architectural property is necessary for the model to make accurate predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
