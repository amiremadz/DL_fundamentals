{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Learn game play from raw pixels with Keras neural network\n",
    "------- \n",
    "\n",
    "![](http://www.reactiongifs.com/r/mgc.gif)\n",
    "\n",
    "Sources:   \n",
    "\n",
    "- [Blog post](http://edersantana.github.io/articles/keras_rl/)  \n",
    "- [Code](https://gist.github.com/EderSantana/c7222daa328f0e885093)  \n",
    "- [Notebook](https://gist.github.com/cadurosar/bd54c723c1d6335a43c8)\n",
    "\n",
    "WARNINGS:\n",
    "\n",
    "- The code is kinda janky and the current frame rate might cause a seizure. \n",
    "- Note that Deep Q-Learning has its own patent by Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catch Game\n",
    "------\n",
    "\n",
    "![](http://edersantana.github.io/articles/keras_rl/catch.gif)\n",
    "\n",
    "Catch a single pixel “fruit” using a three pixel “basket”. \n",
    "\n",
    "he fruit falls one pixel per step and the Keras network gets a reward of +1 if it catches the fruit and -1 otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "from keras.models import model_from_json, Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn\n",
    "\n",
    "from qlearn import Catch, ExperienceReplay\n",
    "\n",
    "seaborn.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__: For the game of _Catch_, what is the:\n",
    "\n",
    "- environment\n",
    "- agent\n",
    "- actions\n",
    "- reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__: Where in the code is the Reinforcement Learning? How does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__: Reinforcement Learning has a notion of exploration. Where in the code is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__: Does a greedy algorithm work for the game of Catch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_screen(action, points, input_t):\n",
    "    global last_frame_time\n",
    "    display.clear_output(wait=True)\n",
    "    print(\"Action {}, Points: {}\".format(translate_action[int(action)], points))\n",
    "    if (\"End\" not in translate_action[int(action)]) :\n",
    "        plt.imshow(input_t.reshape((grid_size,)*2),\n",
    "                   interpolation='none', \n",
    "                   cmap='gray')\n",
    "        display.display(plt.gcf())\n",
    "    last_frame_time = set_max_fps(last_frame_time)\n",
    "\n",
    "def set_max_fps(last_frame_time, FPS = 1):\n",
    "    current_milli_time = lambda: int(round(time.time() * 1000))\n",
    "    sleep_time = 1./FPS - (current_milli_time() - last_frame_time)\n",
    "    if sleep_time > 0:\n",
    "        time.sleep(sleep_time)\n",
    "    return current_milli_time()\n",
    "\n",
    "def test(model):\n",
    "    \"Test pretrained Keras model to play catch\"\n",
    "    global last_frame_time\n",
    "    plt.ion()\n",
    "    # Define environment, game\n",
    "    env = Catch(grid_size)\n",
    "    c = 0\n",
    "    last_frame_time = 0\n",
    "    points = 0\n",
    "    for e in range(10):\n",
    "        loss = 0.\n",
    "        env.reset()\n",
    "        game_over = False\n",
    "        # get initial input\n",
    "        input_t = env.observe()\n",
    "        display_screen(3,points,input_t)\n",
    "        c += 1\n",
    "        while not game_over:\n",
    "            input_tm1 = input_t\n",
    "            # get next action\n",
    "            q = model.predict(input_tm1)\n",
    "            action = np.argmax(q[0])\n",
    "            # apply action, get rewards and new state\n",
    "            input_t, reward, game_over = env.act(action)\n",
    "            points += reward\n",
    "            display_screen(action,points,input_t)\n",
    "            c += 1\n",
    "    display_screen(4,points,input_t)\n",
    "\n",
    "def train(model, n_epochs):\n",
    "    \"Train Keras model to play catch\"\n",
    "    win_cnt = 0\n",
    "    for e in range(n_epochs):\n",
    "        loss = 0.\n",
    "        env.reset()\n",
    "        game_over = False\n",
    "        # get initial input\n",
    "        input_t = env.observe()\n",
    "\n",
    "        while not game_over:\n",
    "            input_tm1 = input_t\n",
    "            # get next action\n",
    "            if np.random.rand() <= epsilon:\n",
    "                action = np.random.randint(0, num_actions, size=1)\n",
    "            else:\n",
    "                q = model.predict(input_tm1)\n",
    "                action = np.argmax(q[0])\n",
    "\n",
    "            # apply action, get rewards and new state\n",
    "            input_t, reward, game_over = env.act(action)\n",
    "            if reward == 1:\n",
    "                win_cnt += 1\n",
    "\n",
    "            # store experience\n",
    "            exp_replay.remember([input_tm1, action, reward, input_t], game_over)            \n",
    "\n",
    "            # adapt model\n",
    "            inputs, targets = exp_replay.get_batch(model, batch_size=batch_size)\n",
    "\n",
    "            display_screen(action, 3000, inputs[0])            \n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "\n",
    "        print(\"Epoch {:03d}| Loss {:.4f} | Win count {}\".format(e, loss, win_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters \n",
    "grid_size = 10\n",
    "max_memory = 500\n",
    "last_frame_time = 0\n",
    "translate_action = [\"Left\", \"Stay\", \"Right\", \"Create Ball\", \"End Test\"]\n",
    "epsilon = .1  # exploration\n",
    "num_actions = 3  # [move_left, stay, move_right]\n",
    "epoch = 1000\n",
    "hidden_size = 100\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_size, input_shape=(grid_size**2,), activation='relu'))\n",
    "model.add(Dense(hidden_size, activation='relu'))\n",
    "model.add(Dense(num_actions))\n",
    "model.compile(sgd(lr=.2), \"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__: Summarize this model in a couple of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__: How does this Keras NN connect to the Reinforcement Learning reward? For example, what is the training signal for backprop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Stay, Points: 3000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAD3CAYAAAAqu3lQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLRVi0FIhBi0VYtBSIf8H3ogQnGE6Av4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117057d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009| Loss 0.4391 | Win count 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAD3CAYAAAAqu3lQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLRVi0FIhBi0VYtBSIf8H3ogQnGE6Av4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117057d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define environment/game\n",
    "env = Catch(grid_size)\n",
    "\n",
    "# Initialize experience replay object\n",
    "exp_replay = ExperienceReplay(max_memory=max_memory)\n",
    "\n",
    "# Train Keras model to play Catch\n",
    "train(model=model,\n",
    "      n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action End Test, Points: -4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAD3CAYAAAAqu3lQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuRJKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116f0e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train Keras model to play Catch\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__: Train model to get max points in test. You can tune current model or define another architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
