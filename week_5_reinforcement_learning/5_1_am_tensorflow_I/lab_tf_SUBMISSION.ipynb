{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TensorFlow SGD Lab\n",
    "\n",
    "Welcome to the TensorFlow SGD Lab! By the end of this lab you will have\n",
    "\n",
    "- Defined and optimized a TensorFlow computational graph to perform classification\n",
    "- Used TensorBoard summary operations to visualize performance during training\n",
    "- Used TensorBoard to visualize your computational graph\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "---\n",
    "\n",
    "# Load Data\n",
    "\n",
    "The following code loads the [Boston housing price regression dataset](http://neupy.com/2015/07/04/boston_house_prices_dataset.html) via [keras](https://keras.io/datasets/) and discretizes the output space into four classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((400, 13), (400, 1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "nb_train = 400\n",
    "np.random.seed(42)\n",
    "\n",
    "[X_boston, y_boston], _ = boston_housing.load_data()\n",
    "X_boston, y_boston = X_boston[:nb_train], y_boston[:nb_train]\n",
    "sorted_idxs = np.argsort(y_boston)\n",
    "X_boston, y_boston = X_boston[sorted_idxs], y_boston[sorted_idxs]\n",
    "y_boston = np.hstack([np.full(shape=100, fill_value=i) for i in range(4)])\n",
    "idxs = np.arange(nb_train)\n",
    "np.random.shuffle(idxs)\n",
    "X_boston, y_boston = X_boston[idxs], y_boston[idxs]\n",
    "\n",
    "y_boston = np.expand_dims(y_boston, axis=-1)\n",
    "X_boston.shape, y_boston.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_boston))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_one_hot = dense_to_one_hot(y_boston,num_classes=len(np.unique(y_boston)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 13), (400, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_boston.shape, y_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Task\n",
    "\n",
    "- Define and optimize a multiclass logistic regression classifier with TensorFlow\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Use TensorBoard to visualize your loss over time as well as your computational graph\n",
    "- Perform optimization with stochastic gradient descent\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "- Take a screenshot of your computational graph and loss in TensorBoard\n",
    "- Remark on your optimized model on whether it fits the data well (e.g. underfits or overfits)\n",
    "    - If your final model still does not fit the data well describe what you would try if you had more time and why\n",
    "\n",
    "## Hints\n",
    "\n",
    "- Attach a `tf.summary.scalar()` node to your loss node so TensorBoard can log its values over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 13], name='X')\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 4], name='y')\n",
    "W = tf.Variable(initial_value=tf.zeros(shape=[13, 4]), name='W')\n",
    "b = tf.Variable(initial_value=tf.zeros(shape=[4]), name='b')\n",
    "\n",
    "z = tf.matmul(X, W, name='z')\n",
    "y = tf.add(z, b, name='y')\n",
    "\n",
    "y_pred = tf.placeholder(tf.float32, [None, 4], name='y_pred')\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_pred, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_summary = tf.summary.scalar(name='loss_summary', tensor=cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01, name='Optimizer')\n",
    "sgd_step = optimizer.minimize(cross_entropy, name='SGDStep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.00846556 -0.0064471  -0.00237837  0.01729103]\n",
      "b: 4.88944e-11\n",
      "W: [-0.00748947 -0.00345255  0.0046849   0.00625711]\n",
      "b: 0.0025\n",
      "W: [-0.00651338 -0.00045799 -0.02601842  0.0329898 ]\n",
      "b: 0.005\n",
      "W: [-0.00553729 -0.03523004 -0.01895513  0.05972248]\n",
      "b: 0.00749999\n",
      "W: [-0.04232779 -0.03223549 -0.01189185  0.08645517]\n",
      "b: 9.31323e-10\n",
      "W: [-0.0413517  -0.02924094 -0.00482856  0.07542124]\n",
      "b: 0.0025\n",
      "W: [-0.04037561 -0.02624638 -0.03553189  0.10215392]\n",
      "b: 0.005\n",
      "W: [-0.03939952 -0.06101843 -0.0284686   0.12888661]\n",
      "b: 0.0075\n",
      "W: [-0.06547347 -0.05802388 -0.02140532  0.14490272]\n",
      "b: 0.000650002\n",
      "W: [-0.06449737 -0.05502933 -0.0143655   0.13389225]\n",
      "b: 0.00315\n",
      "W: [-0.06352128 -0.05203477 -0.04506882  0.16062494]\n",
      "b: 0.00565\n",
      "W: [-0.06254561 -0.07467472 -0.03800553  0.17522593]\n",
      "b: 0.00812351\n",
      "W: [-0.08648803 -0.07168017 -0.03094225  0.18911052]\n",
      "b: 0.00142351\n",
      "W: [-0.08551194 -0.06868648 -0.02400196  0.17820044]\n",
      "b: 0.00392351\n",
      "W: [-0.08453584 -0.06615535 -0.05424186  0.20493312]\n",
      "b: 0.00642351\n",
      "W: [-0.10615779 -0.0631608  -0.04717857  0.21649723]\n",
      "b: 2.40798e-05\n",
      "W: [-0.1051817  -0.07534039 -0.04011529  0.22063744]\n",
      "b: 0.00252408\n",
      "W: [-0.10420561 -0.07234584 -0.04827513  0.22482663]\n",
      "b: 0.00502408\n",
      "W: [-0.10429435 -0.06935129 -0.04121184  0.21485753]\n",
      "b: 0.00254091\n",
      "W: [-0.10331826 -0.0889783  -0.03414856  0.22644517]\n",
      "b: 0.0050409\n",
      "CPU times: user 200 ms, sys: 26.4 ms, total: 226 ms\n",
      "Wall time: 193 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "writer = tf.summary.FileWriter(\"tensorboard/LR with Loss Summary\", sess.graph)\n",
    "for i in range(20):\n",
    "    ls, _ , W_, b_= sess.run([loss_summary, sgd_step, W, b], feed_dict={X: X_boston, y_pred: y_one_hot})\n",
    "    print(\"W:\",W_[0])\n",
    "    print(\"b:\",b_[0])\n",
    "    writer.add_summary(ls, global_step=i)\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Summary (Tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"loss_summary.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bonus Tasks\n",
    "\n",
    "- Add hidden layers to your multiclass logistic regression classifier\n",
    "- Use another optimizer such as adam or adagrad instead of stochastic gradient descent\n",
    "- Monitor the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
